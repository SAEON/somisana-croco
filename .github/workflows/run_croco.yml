name: run croco configuration

on:
  workflow_call:
    inputs:
      RUN_DATE:
        description: 'time of T0 of the model run in format YYYYMMDD_HH - defined dynamically in run_ops.yml'
        required: true
        type: string
      BRANCH_REF:
        description: 'what branch are we on - defined dynamically in run_ops.yml'
        required: true
        type: string
      RUNNER_NAME:
        description: 'specify the runner name to determine what server we are running on'
        required: true
        type: string
      MODEL:
        description: 'directory name used to define the model e.g.croco_v1.3.1'
        required: true
        type: string
      DOMAIN:
        description: 'directory name used to define the domain e.g. sa_west_02' 
        required: true
        type: string
      VERSION:
        description: 'the version used in the archiving directory e.g. v1.0 (this is intended to handle major changes to the model in the forecasts)' 
        required: true
        type: string
      COMP:
        description: 'directory corresponding to the CROCO compilation options e.g. C01' 
        required: true
        type: string
      INP:
        description: 'directory corresponding to the CROCO run-time input options e.g. I01' 
        required: true
        type: string
      BLK:
        description: 'name of bulk forcing e.g. GFS' 
        required: true
        type: string
      TIDE_FRC:
        description: 'name of tidal forcing e.g. TPXO10' 
        required: true
        type: string
      OGCM:
        description: 'name of boundary forcing e.g. MERCATOR' 
        required: true
        type: string
      HDAYS:
        description: 'number of hindcast days (integer) from T0'
        required: true
        type: string
      FDAYS:
        description: 'number of forecast days (integer) from T0'
        required: true
        type: string

env:
  # define the directory names for this configuration
  # unfortunately it looks like you can't use vars defined here to define others i.e. you can't use {{ env.* }} inside this block, you have to use {{ inputs.* }} for each var
  BRANCH_DIR: /home/somisana/ops/${{ inputs.BRANCH_REF }}
  DATE_DIR: /home/somisana/ops/${{ inputs.BRANCH_REF }}/${{ inputs.RUN_DATE }}
  DATA_DIR: /home/somisana/ops/${{ inputs.BRANCH_REF }}/${{ inputs.RUN_DATE }}/downloaded_data
  CONFIG_DIR: /home/somisana/ops/${{ inputs.BRANCH_REF }}/${{ inputs.RUN_DATE }}/${{ inputs.DOMAIN }}/${{ inputs.MODEL }}
  RUN_NAME: ${{ inputs.COMP }}_${{ inputs.INP }}_${{ inputs.OGCM }}_${{ inputs.BLK }}_${{ inputs.TIDE_FRC }}

jobs:
  setup_rundir:
    runs-on: ${{ inputs.RUNNER_NAME }}
    outputs:
      RUN_DIR: ${{ steps.make_dir.outputs.run_dir }}
      SCRATCH_DIR: ${{ steps.make_dir.outputs.scratch_dir }}
    continue-on-error: true
    steps:
      - name: create the run directory
        id: make_dir
        run: |
          sudo rm -rf ${{ env.CONFIG_DIR }}/${{ env.RUN_NAME }}  
          mkdir -p ${{ env.CONFIG_DIR }}/${{ env.RUN_NAME }}/{scratch,output,postprocess}
          chown -R :runners ${{ env.CONFIG_DIR }}/${{ env.RUN_NAME }}
          chmod -R 775 ${{ env.CONFIG_DIR }}/${{ env.RUN_NAME }}
          # output dirs for use in other jobs
          echo "run_dir=${{ env.CONFIG_DIR }}/${{ env.RUN_NAME }}" >> $GITHUB_OUTPUT 
          echo "scratch_dir=${{ env.CONFIG_DIR }}/${{ env.RUN_NAME }}/scratch" >> $GITHUB_OUTPUT 
          echo "output_dir=${{ env.CONFIG_DIR }}/${{ env.RUN_NAME }}/output" >> $GITHUB_OUTPUT 
          echo "postprocess_dir=${{ env.CONFIG_DIR }}/${{ env.RUN_NAME }}/postprocess" >> $GITHUB_OUTPUT 
  
  get_input_files:
    needs: [setup_rundir]
    runs-on: ${{ inputs.RUNNER_NAME }}
    env:
      SCRATCH_DIR: ${{ needs.setup_rundir.outputs.SCRATCH_DIR}}
    steps:
      - name: copy restart/ini file to scratch dir
        id: get_ini
        run: |
          # get the run_date as an epoch time (seconds since 1970-01-01)
          run_date=${{ inputs.RUN_DATE }}
          run_date_epoch_time=$(date -d "${run_date:0:4}-${run_date:4:2}-${run_date:6:2} ${run_date:9:2}:00:00" +%s)
          # current_date starts at run_date and gets changed iteratively in the while loop below
          current_date=${{ inputs.RUN_DATE }} 
          step_count=0
          # MAX_STEPS defines the number of 6 hour steps back to look for a restart file 
          # It's not obvious to me what this should be. Of course we prefer to restart from our model rather than the global model
          # But the further go back to look for a restart file, the more of a forecast solution you're using
          # So it's a trade-off between the most recent global solution vs an older high res solution
          MAX_STEPS=12 

          while [[ $step_count -lt $MAX_STEPS ]]; do

            # Calculate previous date (6 hours back)
            # Convert the datetime to epoch time (seconds since 1970-01-01)
            epoch_time=$(date -d "${current_date:0:4}-${current_date:4:2}-${current_date:6:2} ${current_date:9:2}:00:00" +%s)
            # Subtract 6 hours in seconds (6 hours * 60 minutes * 60 seconds)
            current_date_epoch_time=$((epoch_time - 6 * 60 * 60))
            # update $current_date
            current_date=$(date -d "@$current_date_epoch_time" +%Y%m%d_%H)

            # restart file to look for
            rst_file="${{ env.BRANCH_DIR }}/${current_date}/${{ inputs.DOMAIN }}/${{ inputs.MODEL }}/${{ env.RUN_NAME }}/output/croco_rst.nc"

            # Check if the file exists
            if [[ -f "$rst_file" ]]; then
              echo "restart file found at: $rst_file"
              echo "copy to ${{ env.SCRATCH_DIR }}/croco_ini.nc"
              cp $rst_file ${{ env.SCRATCH_DIR }}/croco_ini.nc
              # compute the number of 6 hourly intervals between run_date and current_date - 
              # this is needed to edit the .in file so we initialise from the correct time-step in the restart file
              # (I guess I could have rather used $step_count + 1 here... should be same difference)
              rst_step=$(((run_date_epoch_time - current_date_epoch_time) / (3600*6)))

              # Exit the loop since the restart file is found
              break
            else
              echo "restart file not found: $rst_file"
              step_count=$((step_count + 1))
            fi
          done

          if [[ $step_count -eq $MAX_STEPS ]]; then
            # use the ini file interpolated from the OGCM data
            echo "using ${{ inputs.OGCM }} to interpolate initial conditions"
            ini_file="${{ env.CONFIG_DIR }}/${{ inputs.OGCM }}/croco_ini_${{ inputs.OGCM }}_${{ inputs.RUN_DATE }}.nc"
            cp ${ini_file} ${{ env.SCRATCH_DIR }}/croco_ini.nc
            # since we're using an ini file from the OGCM data, set rst_step to 1 i.e. the first (and only) value in the ini file 
            echo "rst_step=1" >> $GITHUB_OUTPUT
          else
            echo "rst_step=$rst_step" >> $GITHUB_OUTPUT
          fi
      
      - name: copy OGCM boundary file to scratch dir
        id: get_bry
        run: |
          ogcm_file="${{ env.CONFIG_DIR }}/${{ inputs.OGCM }}/croco_bry_${{ inputs.OGCM }}_${{ inputs.RUN_DATE }}.nc"
          cp ${ogcm_file} ${{ env.SCRATCH_DIR }}/croco_bry.nc
      
      - name: copy tidal forcing file to scratch dir
        id: get_frc
        run: |
          frc_file="${{ env.CONFIG_DIR }}/${{ inputs.TIDE_FRC }}/croco_frc_${{ inputs.TIDE_FRC }}_${{ inputs.RUN_DATE }}.nc"
          cp ${frc_file} ${{ env.SCRATCH_DIR }}/croco_frc.nc
      
      - name: copy BLK files to scratch dir
        id: get_blk
        # even though we are using ONLINE interpolation, let's copy the BLK data to this model run scratch dir 
        # so there are no issues with multiple parallel runs trying to access the same file
        run: |
          cp ${{ env.DATA_DIR }}/${{ inputs.BLK }}/for_croco/* ${{ env.SCRATCH_DIR }}
  
      - name: prepare the runtime input file
        id: get_inp
        run: |
          # compute the time parameters, using the my_env_in.sh file for this configuration
          source ${{ env.CONFIG_DIR }}/${{ inputs.INP }}/myenv_in.sh
          HDAYS=${{ inputs.HDAYS }}
          FDAYS=${{ inputs.FDAYS }}
          # NDAYS=$((HDAYS + FDAYS))
          # the use of 'awk' below allows for HDAYS or FDAYS to include decimal points
          NDAYS=$(awk "BEGIN {print $HDAYS + $FDAYS}")
          NUMTIMES=$(awk "BEGIN {print int($NDAYS * 24 * 3600 / $DT)}")
          NUMAVG=$((NH_AVG * 3600 / DT))
          NUMHIS=$((NH_HIS * 3600 / DT))
          # NUMSTA=$((NH_STA * 3600 / DT)) - station output not getting used as we can easily extract time-series as a postprocessing step
          NUMAVGSURF=$((NH_AVGSURF * 3600 / DT))
          NUMHISSURF=$((NH_HISSURF * 3600 / DT))
          NUMRST=$((NH_RST * 3600 / DT)) # frequency of output in restart file to be written
          RST_STEP=${{ steps.get_ini.outputs.rst_step }} # which time-step to restart from in this run
          # directory where the surface files are for ONLINE interpolation 
          # (this is the path inside the docker image which runs the model!)
          # DATA_DIR_BLK=/home/somisana/${{ env.RUN_NAME }}/scratch/
          # (this is what the path would have been if we weren't running the model inside a docker image)
          DATA_DIR_BLK=${{ env.DATA_DIR }}/${{ inputs.BLK }}/for_croco/
          #
          # do a sed replacement on the template .in file, and write the output to the scratch dir
          sed -e 's|DTNUM|'$DT'|' \
            -e 's|DTFAST|'$DTFAST'|' \
            -e 's|NUMTIMES|'$NUMTIMES'|' \
            -e 's|NUMHISSURF|'$NUMHISSURF'|' \
            -e 's|NUMAVGSURF|'$NUMAVGSURF'|' \
            -e 's|NUMHIS|'$NUMHIS'|' \
            -e 's|NUMAVG|'$NUMAVG'|' \
            -e 's|RST_STEP|'$RST_STEP'|' \
            -e 's|NUMRST|'$NUMRST'|' \
            -e 's|DATA_DIR|'${DATA_DIR_BLK}'|' \
            < ${{ env.CONFIG_DIR }}/${{ inputs.INP }}/croco_fcst.in \
            > ${{ env.SCRATCH_DIR }}/croco.in

      - name: copy grid file to scratch dir
        id: get_grd
        run: |
          cp ${{ env.CONFIG_DIR }}/GRID/croco_grd.nc ${{ env.SCRATCH_DIR }}

      - name: copy croco executable file to scratch dir
        id: get_exe
        run: |
          cp ${{ env.CONFIG_DIR }}/${{ inputs.COMP }}/croco ${{ env.SCRATCH_DIR }}

  # run the model
  run_croco:
    needs: [setup_rundir,get_input_files]
    env:
      RUN_DIR: ${{ needs.setup_rundir.outputs.RUN_DIR}}
      SCRATCH_DIR: ${{ needs.setup_rundir.outputs.SCRATCH_DIR}}
    runs-on: ${{ inputs.RUNNER_NAME }}
    steps:
      - name: run the model
        run: |
          # The commented block of code below corresponds to how one would run the model inside a container
          # by running the ghcr.io/saeon/somisana-croco_run_main:latest image
          #
          # get ${MPI_NUM_PROCS} i.e. the number of cpus to assign to the container
          # (this is an attempt to avoid the container from overloading the server, which has been an issue)
          # source ${{ env.CONFIG_DIR }}/myenv_frcst.sh
          #docker run \
          #  --rm \
          #  --entrypoint /bin/bash \
          #  --cpus=${MPI_NUM_PROCS} \
          #  -v ${{ env.CONFIG_DIR }}:/home/somisana \
          #  ghcr.io/saeon/somisana-croco_run_main:latest \
          #    -c "cd /home/somisana && ./run_croco_frcst.bash ${{ env.RUN_NAME }}"
          #
          # We are preferring to rather run CROCO directly on the server due to issues with resource management
          cd ${{ env.CONFIG_DIR }} && ./run_croco_frcst.bash ${{ env.RUN_NAME }}
      - name: ensure permissions
        run: |
          chmod -R 775 ${{ env.RUN_DIR }}
